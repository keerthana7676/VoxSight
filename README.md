# VoxSight: A Command-Based Voice Assistant for the Visually Impaired

## Project Description
VoxSight is an Android-based assistive application designed to help visually impaired individuals live with more freedom and confidence. [cite_start]The app is a voice-activated assistant that operates completely offline, eliminating the need for an internet connection for its core functions[cite: 5, 6, 19].

By using simple voice commands, users can perform a variety of tasks and receive audio feedback in return. [cite_start]The app's primary goal is to address the accessibility gap and provide meaningful technological support to help people with visual impairments lead a safer and more connected life[cite: 13].

## Features
[cite_start]VoxSight is designed to be a lightweight, responsive, and user-friendly tool that combines machine learning and voice interaction to provide independence to its users[cite: 36, 38].

Key features include:

* [cite_start]**Offline Functionality**: The application can be used entirely offline, ensuring reliability in areas with low or no internet connectivity[cite: 6, 117].
* [cite_start]**Voice-Activated Calling and Messaging**: Users can make phone calls or send and receive text messages hands-free, simply by speaking their commands[cite: 7, 27, 29].
* **Object Detection**: Using the device's camera and an on-device machine learning model, VoxSight can detect and announce nearby objects in real-time. [cite_start]This helps users become more aware of their surroundings and increases their mobility and safety[cite: 8, 33, 34].
* [cite_start]**Real-time Information**: The app can provide real-time audio updates on the current time, date, and battery status with a simple voice command[cite: 7, 31].
* [cite_start]**User-Centric Design**: The user interface is minimal and relies primarily on audio feedback, making it compliant with voice interaction and compatible with screen readers for an easy-to-use experience[cite: 12, 37].

## Technology Stack
[cite_start]The VoxSight application is built on the following technologies to ensure it is technically viable, efficient, and reliable[cite: 120, 121]:

* [cite_start]**Development Environment**: Android Studio [cite: 10, 35]
* [cite_start]**Languages**: Java and Kotlin [cite: 10, 35]
* [cite_start]**Machine Learning**: TensorFlow Lite for on-device machine learning models, including YOLOv10-N for real-time object detection[cite: 11, 35, 121].
* [cite_start]**APIs**: Text-to-Speech (TTS) and Speech Recognition APIs for voice interaction[cite: 122].

## Feasibility
* [cite_start]**Technical**: The app uses stable and well-documented technologies like Android Studio and TensorFlow Lite, which work on most Android devices without needing extra hardware[cite: 120, 121, 123].
* [cite_start]**Operational**: Its voice-first design makes it intuitive and easy to use with minimal learning, and its offline capability ensures it functions reliably in rural or remote areas[cite: 124, 126].
* [cite_start]**Economic**: The project uses open-source tools and is designed for mid-range Android phones, making it a cost-effective solution for both development and end users[cite: 127, 128, 129].

## Future Enhancements
[cite_start]The app's modular design allows for future improvements to enhance its functionality and inclusivity[cite: 320, 326]. Potential future enhancements include:

* [cite_start]**Multilingual Voice Support**: Adding support for regional languages to reach a wider audience in a multilingual country like India[cite: 327, 328].
* [cite_start]**Optical Character Recognition (OCR)**: Implementing an AI-based OCR feature to allow the app to read text from books, signs, and labels[cite: 329].
* [cite_start]**Real-time Navigation**: Integrating GPS and voice-guided instructions to help users navigate unfamiliar environments with greater confidence[cite: 330, 331].
* [cite_start]**Distress Alert**: A voice-activated distress feature that could alert emergency services or close contacts with the user's real-time location[cite: 334].

## Contribution
We welcome contributions to the VoxSight project. For any suggestions or bug reports, please feel free to open an issue.
